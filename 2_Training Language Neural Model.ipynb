{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Language Neural Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train a statistical language model from the prepared data.\n",
    "\n",
    "The model we will train is a neural language model. It has a few unique characteristics:\n",
    "\n",
    "(a) It uses a distributed representation for words so that different words with similar meanings will have a similar representation.\n",
    "(b) It learns the representation at the same time as learning the model.\n",
    "(c) It learns to predict the probability for the next word using the context of the last 10 words.\n",
    "\n",
    "First, let's input the encoded data from 'encoded_sequences' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('encoded_sequences/encoded_training_20pc_300.csv')\n",
    "validation_data = pd.read_csv('encoded_sequences/encoded_validation_20pc_300.csv')\n",
    "testing_data = pd.read_csv('encoded_sequences/encoded_testing_20pc_300.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 300 # Length of input sequence\n",
    "\n",
    "a = list(range(0, N))\n",
    "a = [str(i) for i in a]\n",
    "XTrain = np.array(train_data[a])\n",
    "YTrain = np.array(train_data[str(N)])\n",
    "XVal = np.array(validation_data[a])\n",
    "YVal = np.array(validation_data[str(N)])\n",
    "XTest = np.array(testing_data[a])\n",
    "YTest = np.array(testing_data[str(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the length of the vocabulary is 16689. So, we will one-hot encode the Y vectors for the train, validation, test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One - Hot Encoding for Training Set\n",
    "oh_YTrain = []\n",
    "for j in range(len(YTrain)):\n",
    "    temp = np.zeros(16689)\n",
    "    temp[YTrain[j]] = 1\n",
    "    oh_YTrain.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One - Hot Encoding for Validation set\n",
    "oh_YVal = []\n",
    "for j in range(len(YVal)):\n",
    "    temp = np.zeros(16689)\n",
    "    temp[YVal[j]] = 1\n",
    "    oh_YVal.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One - Hot Encoding for Test set\n",
    "oh_YTest = []\n",
    "for i in range(len(YTest)):\n",
    "    temp = np.zeros(16689)\n",
    "    temp[YTest[i]] = 1\n",
    "    oh_YTest.append(list(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_shape = np.array(XTrain).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising a sequential LSTM model with 2 hidden layers with 100 nodes each\n",
    "\n",
    "model = Sequential()  \n",
    "model.add(Embedding(16689, N, input_length=inp_shape))\n",
    "model.add(LSTM(100, return_sequences=True))  \n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(16689, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit model\n",
    "model.fit(XTrain, np.asarray(oh_YTrain), batch_size=128, epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for each word\n",
    "y_hat = model.predict_classes(XTest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: '+ str(np.mean(y_hat == YTest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
